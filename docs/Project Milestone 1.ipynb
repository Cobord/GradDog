{"cells":[{"cell_type":"markdown","source":"# PackageName: Calculus Software Library in Python\n\n### Peyton Benac, Max Cembalest, Seeam Shahid Noor, Guanhua Shu","metadata":{"cell_id":"00000-7b27ba50-c0fb-4660-a2bc-cdddc5effbd4"}},{"cell_type":"markdown","source":"## Introduction\n\n![alt](dog.jpg)\n\nIn engineering, statistical modelling, and countless other scientific disciplines, derivatives are calculated to measure change in a dynamic system. It is crucial for professionals of all kinds who work with quantitative systems to have access to software that can calculate derivatives quickly, efficiently, and with a simple-to-use interface. That is why TensorFlow exists. Our software package, PackageName, will try to do the same.\n\nPackageName performs automatic differentiation to machine precision, as well as *insert task here*. We walk through some of the mathematics of automatic differentiation, as well as some basic information about the usage of our library.","metadata":{"cell_id":"00001-522f1ca3-45d6-4e5d-913e-c5fa6cfcf992"}},{"cell_type":"markdown","source":"## Background\n\nComputing gradients the old-fashioned way (by hand) is certainly feasible for many mathematical functions that appear in many applications. A key step in almost every derivative is known as the chain rule, which applies whenever our function's inner structure is a composition of functions, e.g.,\n\n$$f(x, y) = g(h(x, y))$$\n\nThe chain rule states that\n\n$$\\frac{df}{dx} = \\frac{dg}{dx}(h(x, y))\\frac{dh}{dx}(x, y)$$\n\n\n\nHere's an example of computing the gradients of the function $f(x, y) = \\sin(2x + 3y)e^{-x^2}$\n\nThe partial derivative $\\partial f/\\partial x$ can be calculated using the product rule and the chain rule:\n\n$$\\partial f/\\partial x = \\sin(2x + 3y)(-2x)e^{-x^2} + 2\\cos(2x + 3y)e^{-x^2}$$\n\nThe partial derivative $\\partial f/\\partial y$ only needs to be calculated using the chain rule, since a term only involving x is constant with respect to y:\n\n$$\\partial f/\\partial y = 3\\cos(2x + 3y)e^{-x^2}$$\n\n\n","metadata":{"cell_id":"00002-72b39e4a-26d1-4204-9857-6b63d39fb534"}},{"cell_type":"markdown","source":"We can represent the function's individual operations in a graphical format:\n\n![alt](func_graph.jpeg)\n\nBy parsing the structure of the function f(x, y) into its atomic building blocks, we can construct a trace table from which we can read the results of the chain rule at every step of the computation.","metadata":{"cell_id":"00003-e31fe64e-dbd6-43c8-8125-d4ace855e048"}},{"cell_type":"markdown","source":"The fact that this process is *automatic* comes very much in handy when computing gradients of more complex functions, for example:\n\n$$f(x,y) = 3sin(e^{6x - ln(4y^3 - 3x^2)} + 17\\sqrt{y^5-tanh(x)})17(4x^{1/3}+29yln(x - y))^{7/19}$$\n\nYeah, we would prefer not to do that by hand.","metadata":{"tags":[],"cell_id":"00005-1b9d68f1-a01b-459e-917a-400cfcc37eae"}},{"cell_type":"markdown","source":"## How to use *PackageName*","metadata":{"cell_id":"00005-3586651e-49c7-46a4-80a5-1eee2daac899"}},{"cell_type":"code","metadata":{"cell_id":"00006-1076fcc9-dbd8-4987-935f-3312e9edb7f1","output_cleared":false,"source_hash":"88fc57e1","execution_millis":42,"execution_start":1603170306217},"source":"# Sample code\n\nfrom GradDog import variables, gradient\nfrom GradDog.elem_functions import sin, exp\n\nx, y = variables(2)\n\nf = sin(2*x + 3*y)*exp(-x**2)\n\ndfdx = gradient(func = f, with_respect_to = x)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nElementary Functions:\n\nx**r\n\nsin, cos, tan\n\nln, exp\n\nAny function f is either an elementary function, or it is a composite function.\n\nIf f is a composite function, then it satisfies at least one of these five conditions (where g and h also represent functions):\n\n1) f = g + h\n\n2) f = g - h\n\n3) f = g * h\n\n4) f = g / h\n\n5) f = g(h)\n\nAny function that is a composition of these elementary functions and composition operations will be valid inputs to GradDog.gradient","metadata":{"tags":[],"cell_id":"00007-716c1cb0-9590-425d-a504-b03888dd0099"}},{"cell_type":"markdown","source":"We intend to require the user to `import numpy` before using our package. Then, after importing our AD package using (`import GradDog as gd`), \nan AD object can be created by calling `gd.gradient(func, point)` method.","metadata":{"tags":[],"cell_id":"00007-92ec94e4-63ef-4fd4-a0f7-f77d401f4130"}},{"cell_type":"markdown","source":"## Software Organization","metadata":{"tags":[],"cell_id":"00008-22a24c5b-3a42-4a79-958d-412094f688d9"}},{"cell_type":"markdown","source":"We plan to primarily distribute our code by having clients clone our github repo, but we hope to also make it pip-installable.\n\nWe plan to organize our package as follows:\n- documentation in `\\docs`\n- test suite in `\\tests`\n- code in `\\source`\n\nWe plan to include separate modules for the elementary functions, the actual implementation of AD, and for testing.\n\nWe will use both TravisCI and CodeCov, but our test suite will live inside our repo in a `\\tests\\` directory.\n\nTo package our software, we will use [wheels](https://www.python.org/dev/peps/pep-0427/). This should make it easily pip installable.","metadata":{"tags":[],"cell_id":"00010-40123771-430f-4f8a-9349-b691585f8de0"}},{"cell_type":"markdown","source":"## Implementation","metadata":{"tags":[],"cell_id":"00010-813d30f1-2d86-4342-84f3-6c2a0b3b6b9a"}},{"cell_type":"markdown","source":"We plan to implement this using `numpy` arrays as our core data structure, because this will make it easy to perform operations on either single values or single or multidimensional arrays. Our only external dependency should be `numpy`.","metadata":{"tags":[],"cell_id":"00013-af8b9b73-f814-4769-94b9-54858093a137"}},{"cell_type":"markdown","source":"We hope to write a parent class called `Function` and write subclasses for each elementary function. This subclasses will contain the derivative of the elementary function.\nWe will use operator overloading to allow the client to create a composite function (e.g. $sin (e^{2x})$) that we can differentiate.","metadata":{"tags":[],"cell_id":"00014-8b4a308e-81c0-4d7c-894e-3115891eb92b"}},{"cell_type":"markdown","source":"To deal with any elementary functions (like sin, sqrt, exp, log), we will use np's existing function","metadata":{"tags":[],"cell_id":"00011-38198f4a-1a05-499e-bb5a-4ea4ab78129e"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"00012-eba5e3e4-70f2-41d0-9fc8-c9f63b0fe182"}}],"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"deepnote_notebook_id":"a39b2faf-82bf-4c7a-85b6-a3d0fcdccde2","deepnote_execution_queue":[]}}